{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to keep the lecture notebook and seperate out the wine stuff here since it upset me that we were\n",
    "re-setting variable names each time we changed data sets. And also to avoid running the newsgroups cells\n",
    "since that took a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.datasets import fetch_20newsgroups # demo data set \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force Run on TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,3), tokenizer=tokenize)\n",
    "clf = RandomForestClassifier()\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "target = 'ratingCategory'\n",
    "features = 'description'\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "# model and vectorizer parameters\n",
    "pipe_params = {\n",
    "    'vect__max_df': (0.75, 1.0),\n",
    "    'vect__min_df': (0.02, 0.05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators': (5,10),\n",
    "    'clf__max_depth':(5,10,15,20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\nSometimes, when whisky is batched, a few lef...\n",
       "1    \\nAn uncommon exclusive bottling of a 6 year o...\n",
       "2    \\nThis release is a port version of Amrutâ€™s In...\n",
       "3    \\nThis 41 year old single cask was aged in a s...\n",
       "4    \\nQuite herbal on the nose, with aromas of dri...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "grid_search = GridSearchCV(pipe, pipe_params, cv=3, n_jobs=8, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  30 out of  30 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.714705162711035"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random search, working noticeably faster\n",
    "random_search = RandomizedSearchCV(pipe, pipe_params, cv=3, n_jobs=8, verbose=1)\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SVD, removed algorithm arg since it defaults to whatever is most efficient\n",
    "svd = TruncatedSVD(n_components=100, n_iter=3)\n",
    "\n",
    "svd_params = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}\n",
    "\n",
    "# create two seperate pipelines\n",
    "lsi_pipe = Pipeline([('vect', vect), ('svd', svd)])\n",
    "svd_pipe = Pipeline([('lsi', lsi_pipe), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI SVD GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done  81 out of  81 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7191093711769023"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_grid_search = GridSearchCV(svd_pipe, svd_params, cv=3, n_jobs=4, verbose=1)\n",
    "svd_grid_search.fit(X_train, y_train)\n",
    "svd_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI SVD RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7188646929287986"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_random_search = RandomizedSearchCV(svd_pipe, svd_params, cv=3, n_jobs=4, verbose=1)\n",
    "svd_random_search.fit(X_train, y_train)\n",
    "svd_random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "test = nlp(\"And we are never ever ever, getting back together\")\n",
    "taylor_swift_vector = test.vector\n",
    "print(len(taylor_swift_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs: iter):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a4858ed59a40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_word_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_word_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_test_word_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_word_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m rfc_params = {\n\u001b[0;32m      7\u001b[0m             \u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m700\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mdoc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# fit word vectors onto model \n",
    "from scipy.stats import uniform\n",
    "\n",
    "X_train_word_vectors = get_word_vectors(train['description'])\n",
    "X_test_word_vectors = get_word_vectors(test['description'])\n",
    "rfc_params = {\n",
    "            'n_estimators': [200, 700],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']\n",
    "                     }\n",
    "classifier = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to vectorize in order to run predict so use original pipe is fine\n",
    "# running the pipe breaks .fit here \n",
    "spacy_random = RandomizedSearchCV(classifier, rfc_params, n_jobs=4, verbose=1, cv=5)    \n",
    "spacy_random.fit(X_train_word_vectors, y_train)\n",
    "spacy_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_random.predict(X_test_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_grid = GridSearchCV(classifier, rfc_params, n_jobs=4, verbose=1, cv=5)\n",
    "spacy_grid.fit(X_train_word_vectors, y_train)\n",
    "spacy_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_grid.predict(X_test_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(svd_random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(spacy_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"description\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(search, subNumber):\n",
    "    pred = search.predict(test['description'])\n",
    "    submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "    submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "    assert(submission.shape == (1022, 2))\n",
    "    submission.to_csv(f'./data/submission{str(subNumber)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor above to take a third argument and condense these 2 functions\n",
    "\n",
    "def create_transformed_sub(search, subNumber):\n",
    "    pred = search.predict(X_test_word_vectors)\n",
    "    submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "    submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "    assert(submission.shape == (1022, 2))\n",
    "    submission.to_csv(f'./data/submission{str(subNumber)}.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(grid_search, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(random_search, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(svd_grid_search, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(svd_random_search, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_transformed_sub(spacy_grid, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_transformed_sub(spacy_random, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
